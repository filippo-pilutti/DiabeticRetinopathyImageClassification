{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TODO\n",
        "- DONE preprocess su immagini di dimensioni reali, e resizing successivo\n",
        "- migliorare data augmentation in modo che le immagini vengano molto più diverse una dall'altra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare all the dataset\n",
        "Before using the following code, install necessary libraries\n",
        "'pip install pandas opencv-python numpy matplotlib pillow tqdm torch torchvision torchinfo scikit-learn focal-loss-torch'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGwcx61F9Ove"
      },
      "outputs": [],
      "source": [
        "# =========================================================\n",
        "# Librerie standard Python\n",
        "# =========================================================\n",
        "import os\n",
        "import gc\n",
        "import io\n",
        "import csv\n",
        "import json\n",
        "import base64\n",
        "import shutil\n",
        "import random\n",
        "import pathlib\n",
        "import subprocess\n",
        "import itertools\n",
        "from pathlib import Path\n",
        "from typing import Optional, Dict, Any, List, Callable\n",
        "from collections import Counter\n",
        "\n",
        "# =========================================================\n",
        "# Librerie scientifiche e di elaborazione dati\n",
        "# =========================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, confusion_matrix,\n",
        "    precision_score, recall_score, f1_score\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# Librerie per immagini e visualizzazione\n",
        "# =========================================================\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# =========================================================\n",
        "# PyTorch e moduli correlati\n",
        "# =========================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
        "\n",
        "# =========================================================\n",
        "# TorchVision\n",
        "# =========================================================\n",
        "import torchvision\n",
        "from torchvision import transforms, models\n",
        "from torchvision.transforms import functional\n",
        "\n",
        "# =========================================================\n",
        "# Altre librerie\n",
        "# =========================================================\n",
        "from torchinfo import summary\n",
        "from focal_loss.focal_loss import FocalLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbOgqutEaNL9"
      },
      "outputs": [],
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # Unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "use_resized = 0\n",
        "local_runtime = 1\n",
        "download_data_from_drive = 0\n",
        "use_data_preprocessing = 1\n",
        "use_data_augmentation = 1\n",
        "use_subset_loader = 0\n",
        "preprocess_out_size = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_size = 224\n",
        "batch_size = 64\n",
        "\n",
        "# Target per classe della data augmentation: se None, usa la massima numerosità corrente, altrimenti\n",
        "# genera un numero di immagini pari al numero scelto (1000) - quante ce ne sono già\n",
        "TARGET_PER_CLASS = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXjdzS0Y9_Sc"
      },
      "outputs": [],
      "source": [
        "if use_resized == 1:\n",
        "  resized_path = 'resized_512/'\n",
        "else:\n",
        "  resized_path = \"\"\n",
        "drive_zip_path = \"/content/drive/MyDrive/COMPUTER VISION PROJECT/dataset/resized_512/\"\n",
        "\n",
        "if local_runtime==1:\n",
        "    #base_path = \"/Users/ire/Documents/2° Year/SELECTED TOPICS /project/dataset/\"\n",
        "    #base_path = 'C:/Users/s.simonitti/Desktop/DiabeticRetinopathyImageClassification/dataset/'\n",
        "    base_path = \"C:/Users/pippo/Desktop/UNI/AI & CyberSec - Klagenfurt/SelectedTopics/DiabeticRetinopathyImageClassification/dataset/\"\n",
        "else:\n",
        "    base_path = '/content/drive/MyDrive/Colab Notebooks/dataset/'\n",
        "\n",
        "data_dir = base_path + resized_path + 'train_images'\n",
        "val_dir = base_path + resized_path + 'val_images'\n",
        "test_dir = base_path + resized_path + 'test_images'\n",
        "processed_train_dir = base_path + \"processed_dataset/train_images\"\n",
        "processed_val_dir = base_path + \"processed_dataset/val_images\"\n",
        "processed_test_dir = base_path + \"processed_dataset/test_images\"\n",
        "\n",
        "if use_data_augmentation==1:\n",
        "  augm_path=\"augmented_dataset/\"\n",
        "else:\n",
        "  augm_path=\"\"\n",
        "\n",
        "augm_train_dir = base_path + augm_path + \"train_images\"\n",
        "\n",
        "\n",
        "# csv file names\n",
        "train_binary_file = \"train_binary.csv\"\n",
        "train_four_classes_file = \"train_four_classes.csv\"\n",
        "\n",
        "val_binary_file = \"val_binary.csv\"\n",
        "val_four_classes_file = \"val_four_classes.csv\"\n",
        "\n",
        "test_binary_file = \"test_binary.csv\"\n",
        "test_four_classes_file = \"test_four_classes.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if local_runtime==0:\n",
        "    drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download zip dataset from drive and unzip it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFCMkcCR4EZl"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset_zip(\n",
        "    drive_zip_path: str,\n",
        "    local_zip_path: str,\n",
        "    extract_dir: str,\n",
        "    ready_flag: str = \".ready\",\n",
        "    verbose: bool = True,\n",
        "    delete_zip_after_extract: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Copia uno zip da Google Drive, lo estrae localmente in /content,\n",
        "    e cancella lo zip dopo l'estrazione. Usa un file sentinella (.ready)\n",
        "    per evitare di ripetere l'estrazione se già completata.\n",
        "\n",
        "    Args:\n",
        "        drive_zip_path (str): percorso completo allo zip su Drive.\n",
        "        local_zip_path (str): percorso temporaneo per lo zip locale.\n",
        "        extract_dir (str): cartella dove estrarre i file.\n",
        "        ready_flag (str): nome del file sentinella per la cache.\n",
        "        verbose (bool): stampa messaggi di stato se True.\n",
        "        delete_zip_after_extract (bool): se True, rimuove lo zip dopo l'estrazione.\n",
        "\n",
        "    Returns:\n",
        "        str: percorso della cartella estratta (extract_dir)\n",
        "    \"\"\"\n",
        "    extract_dir = os.path.abspath(extract_dir)\n",
        "    ready_file = os.path.join(extract_dir, ready_flag)\n",
        "    pathlib.Path(extract_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if not os.path.exists(ready_file):\n",
        "        if verbose: print(\"Copio lo zip da Drive a /content...\")\n",
        "        shutil.copy(drive_zip_path, local_zip_path)\n",
        "\n",
        "        if verbose: print(\"Estrazione in corso...\")\n",
        "        subprocess.run([\"unzip\", \"-q\", \"-n\", local_zip_path, \"-d\", extract_dir], check=True)\n",
        "\n",
        "        # crea file sentinella\n",
        "        open(ready_file, \"w\").close()\n",
        "        if verbose: print(f\"Dataset pronto in {extract_dir}\")\n",
        "\n",
        "        # rimuove zip locale per liberare spazio\n",
        "        if delete_zip_after_extract and os.path.exists(local_zip_path):\n",
        "            os.remove(local_zip_path)\n",
        "            if verbose: print(f\"File zip locale rimosso: {local_zip_path}\")\n",
        "    else:\n",
        "        if verbose: print(f\"Dataset già estratto in {extract_dir}, uso cache locale.\")\n",
        "\n",
        "    return extract_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGYGbbxTvSPb",
        "outputId": "fcd2e118-518b-4134-a6d3-382f5a87875f"
      },
      "outputs": [],
      "source": [
        "if download_data_from_drive:\n",
        "    data_dir = prepare_dataset_zip(\n",
        "        drive_zip_path=drive_zip_path + \"train_images.zip\",\n",
        "        local_zip_path=base_path + \"train_images.zip\",\n",
        "        extract_dir=data_dir\n",
        "    )\n",
        "    val_dir = prepare_dataset_zip(\n",
        "        drive_zip_path=drive_zip_path + \"val_images.zip\",\n",
        "        local_zip_path=base_path + \"val_images.zip\",\n",
        "        extract_dir=val_dir\n",
        "    )\n",
        "    test_dir = prepare_dataset_zip(\n",
        "        drive_zip_path=drive_zip_path + \"test_images.zip\",\n",
        "        local_zip_path=base_path + \"test_images.zip\",\n",
        "        extract_dir=test_dir\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_images = os.listdir(data_dir)\n",
        "val_images = os.listdir(val_dir)\n",
        "test_images = os.listdir(test_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "I33iWpgS-JBA",
        "outputId": "21502196-32c9-47c5-9dde-44ae261db4ee"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(os.path.join(data_dir, train_images[700]))\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocess images\n",
        "Denoise and other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_retina_image(image_path):\n",
        "    # 1. Load image (RGB)\n",
        "    img = cv2.imread(image_path)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # 2. Cropping eye region (remove black background)\n",
        "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
        "    _, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    # Find largest contour (eye region)\n",
        "    c = max(contours, key=cv2.contourArea)\n",
        "    x, y, w, h = cv2.boundingRect(c)\n",
        "    cropped_img = img_rgb[y:y+h, x:x+w]\n",
        "\n",
        "    # 3. Denoising (Gaussian Blur, kernel size 3x3)\n",
        "    denoised_img = cv2.GaussianBlur(cropped_img, (3, 3), 0)\n",
        "\n",
        "    # 4. Histogram Equalization on Y channel (YUV color space)\n",
        "    img_yuv = cv2.cvtColor(denoised_img, cv2.COLOR_RGB2YUV)\n",
        "    img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
        "    he_img = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2RGB)\n",
        "\n",
        "    final_img = cv2.resize(he_img, (preprocess_out_size, preprocess_out_size))\n",
        "\n",
        "    return final_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_image_batch(\n",
        "    images_to_process,\n",
        "    images_dir,\n",
        "    out_images_dir\n",
        "):\n",
        "    for img_name in tqdm(images_to_process, desc=\"Processing Images\", unit=\"image\"):\n",
        "        # 1. Determina immediatamente il percorso di salvataggio\n",
        "        save_path = os.path.join(out_images_dir, img_name)\n",
        "\n",
        "        # 2. CONTROLLO DI ESISTENZA\n",
        "        if os.path.exists(save_path):\n",
        "            # Se il file esiste, stampa un messaggio e passa all'immagine successiva\n",
        "            # print(f\"Skipping {img_name}: already processed.\")\n",
        "            continue # Passa all'elemento successivo nel ciclo\n",
        "    \n",
        "        # Se il file NON esiste, esegui il processo\n",
        "        img_path = os.path.join(images_dir, img_name)\n",
        "    \n",
        "        try:\n",
        "            # Elaborazione (viene eseguita solo se il file non esiste)\n",
        "            processed_img = preprocess_retina_image(img_path)\n",
        "        \n",
        "            # Salvataggio\n",
        "            cv2.imwrite(save_path, cv2.cvtColor(processed_img, cv2.COLOR_RGB2BGR))\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {img_name}: {e}\")\n",
        "\n",
        "    print(f\"Finished processing and saving images to {out_images_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if use_data_preprocessing:\n",
        "    os.makedirs(processed_train_dir, exist_ok=True)\n",
        "    os.makedirs(processed_val_dir, exist_ok=True)\n",
        "    os.makedirs(processed_test_dir, exist_ok=True)\n",
        "\n",
        "    print(\"Processing training images...\")\n",
        "    process_image_batch(\n",
        "        images_to_process = train_images,\n",
        "        images_dir = data_dir,\n",
        "        out_images_dir = processed_train_dir)\n",
        "\n",
        "    print(\"Processing vaòidation images...\")\n",
        "    process_image_batch(\n",
        "        images_to_process = val_images,\n",
        "        images_dir = val_dir,\n",
        "        out_images_dir = processed_val_dir)\n",
        "\n",
        "    print(\"Processing testing images...\")\n",
        "    process_image_batch(\n",
        "        images_to_process = test_images,\n",
        "        images_dir = test_dir,\n",
        "        out_images_dir = processed_test_dir)\n",
        "else:\n",
        "    processed_train_dir = data_dir\n",
        "    processed_val_dir = val_dir\n",
        "    processed_test_dir = test_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare binary classification labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def crea_file_diagnosis_binaria(input_path: str, output_path: str):\n",
        "    \"\"\"\n",
        "    Legge un file CSV/XLS con una colonna 'diagnosis' e crea un nuovo file\n",
        "    in cui 'diagnosis' vale 0 se è 0, altrimenti 1.\n",
        "    \n",
        "    :param input_path: percorso del file di input (CSV o Excel)\n",
        "    :param output_path: percorso del file di output CSV\n",
        "    \"\"\"\n",
        "    # Legge il file (rileva automaticamente se è CSV o Excel)\n",
        "    df = pd.read_csv(input_path)\n",
        "\n",
        "    # Conversione della colonna 'diagnosis' in 0/1\n",
        "    df['diagnosis'] = df['diagnosis'].apply(lambda x: 0 if x == 0 else 1)\n",
        "\n",
        "    # Salva il nuovo file\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"File con diagnosis binaria salvato in: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "crea_file_diagnosis_binaria(input_path=base_path + \"train.csv.xls\", output_path=base_path + train_binary_file)\n",
        "crea_file_diagnosis_binaria(input_path=base_path + \"val.csv.xls\", output_path=base_path + val_binary_file)\n",
        "crea_file_diagnosis_binaria(input_path=base_path + \"test.csv.xls\", output_path=base_path + test_binary_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare four classes labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def crea_file_diagnosis_nonzero(input_path: str, output_path: str):\n",
        "    \"\"\"\n",
        "    Legge un file CSV/XLS con una colonna 'diagnosis' e crea un nuovo file\n",
        "    contenente solo le righe dove 'diagnosis' è diversa da 0.\n",
        "    \n",
        "    :param input_path: percorso del file di input (CSV o Excel)\n",
        "    :param output_path: percorso del file di output CSV\n",
        "    \"\"\"\n",
        "    # Legge il file (rileva automaticamente se è CSV o Excel)\n",
        "    df = pd.read_csv(input_path)\n",
        "\n",
        "    # Filtra solo le righe con diagnosis diversa da 0\n",
        "    df_filtrato = df[df['diagnosis'] != 0].copy()\n",
        "    df_filtrato['diagnosis'] = df_filtrato['diagnosis'].apply(lambda x: x-1)\n",
        "\n",
        "    # Salva il nuovo file\n",
        "    df_filtrato.to_csv(output_path, index=False)\n",
        "    print(f\"File con diagnosis != 0 salvato in: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "crea_file_diagnosis_nonzero(input_path=base_path + \"train.csv.xls\", output_path=base_path + train_four_classes_file)\n",
        "crea_file_diagnosis_nonzero(input_path=base_path + \"val.csv.xls\", output_path=base_path + val_four_classes_file)\n",
        "crea_file_diagnosis_nonzero(input_path=base_path + \"test.csv.xls\", output_path=base_path + test_four_classes_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FundusAugment:\n",
        "    \"\"\"\n",
        "    Augmentations secondo Tabella 3:\n",
        "    - Zoom range: 0.2  -> scale (0.8, 1.0)\n",
        "    - Rotation range: ±10°\n",
        "    - Flip: orizzontale + verticale\n",
        "    - Brightness/Color(=Saturation)/Contrast: (0.5, 1.5)\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_size: 512,\n",
        "        p_zoom: float = 0.7,\n",
        "        p_hflip: float = 0.5,\n",
        "        p_vflip: float = 0.5,\n",
        "        p_rotate: float = 1,\n",
        "        p_color: float = 1,\n",
        "        zoom_scale=(0.80, 1.00),\n",
        "        zoom_ratio=(0.95, 1.05),\n",
        "        rot_deg: float = 20.0,\n",
        "        brightness=(0.5, 1.5),\n",
        "        contrast=(0.5, 1.5),\n",
        "        color_adjustment=(0.5, 1.5)\n",
        "    ):\n",
        "        self.img_size = img_size\n",
        "        self.p_zoom = p_zoom\n",
        "        self.p_hflip = p_hflip\n",
        "        self.p_vflip = p_vflip\n",
        "        self.p_rotate = p_rotate\n",
        "        self.p_color = p_color\n",
        "        self.zoom_scale = zoom_scale\n",
        "        self.zoom_ratio = zoom_ratio\n",
        "        self.rot_deg = rot_deg\n",
        "        self.resize = transforms.Resize((img_size, img_size))\n",
        "\n",
        "        self.color_jitter = transforms.ColorJitter(\n",
        "            brightness=brightness,\n",
        "            contrast=contrast,\n",
        "            saturation=color_adjustment,\n",
        "            hue=0.0\n",
        "        )\n",
        "\n",
        "    def __call__(self, img: Image.Image) -> Image.Image:\n",
        "        img = self.resize(img)\n",
        "\n",
        "        if random.random() < self.p_zoom:\n",
        "            rrc = transforms.RandomResizedCrop(\n",
        "                self.img_size, scale=self.zoom_scale#, ratio=self.zoom_ratio\n",
        "            )\n",
        "            img = rrc(img)\n",
        "\n",
        "        if random.random() < self.p_hflip:\n",
        "            img = functional.hflip(img)\n",
        "        if random.random() < self.p_vflip:\n",
        "            img = functional.vflip(img)\n",
        "\n",
        "        if random.random() < self.p_rotate:\n",
        "            angle = random.uniform(-self.rot_deg, self.rot_deg)\n",
        "            img = functional.rotate(img, angle, interpolation=Image.BICUBIC, expand=False, fill=0)\n",
        "\n",
        "        if random.random() < self.p_color:\n",
        "            img = self.color_jitter(img)\n",
        "\n",
        "        return img\n",
        "  \n",
        "# -----------------------------\n",
        "# UTILS\n",
        "# -----------------------------\n",
        "EXTS = [\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\", \".bmp\", \".webp\"]\n",
        "\n",
        "def find_image_for_id(id_code: str, root: Path) -> Path | None:\n",
        "    for ext in EXTS:\n",
        "        p = root / f\"{id_code}{ext}\"\n",
        "        if p.exists():\n",
        "            return p\n",
        "    # fallback: cerca per pattern (es. file con id_code come prefisso)\n",
        "    matches = list(root.glob(f\"{id_code}.*\"))\n",
        "    return matches[0] if matches else None\n",
        "\n",
        "def load_df(csv_path: Path) -> pd.DataFrame:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    cols = [c.lower() for c in df.columns]\n",
        "    # normalizza nomi colonne attese\n",
        "    if \"id_code\" in cols and \"diagnosis\" in cols:\n",
        "        return df.rename(columns={df.columns[cols.index(\"id_code\")]: \"id_code\",\n",
        "                                  df.columns[cols.index(\"diagnosis\")]: \"diagnosis\"})\n",
        "    elif \"filepath\" in cols and \"diagnosis\" in cols:\n",
        "        return df.rename(columns={df.columns[cols.index(\"filepath\")]: \"filepath\",\n",
        "                                  df.columns[cols.index(\"diagnosis\")]: \"diagnosis\"})\n",
        "    else:\n",
        "        raise ValueError(\"CSV deve avere colonne (id_code,diagnosis) oppure (filepath,diagnosis).\")\n",
        "\n",
        "def row_to_path(row, dir_img) -> Path:\n",
        "    if \"filepath\" in row and isinstance(row[\"filepath\"], str):\n",
        "        return Path(row[\"filepath\"])\n",
        "    # se abbiamo id_code, cerchiamo il file nella cartella root\n",
        "    return find_image_for_id(str(row[\"id_code\"]), dir_img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if use_data_augmentation==1:\n",
        "  # Percorsi\n",
        "  TRAIN_IMG_DIR = Path(processed_train_dir)\n",
        "  TRAIN_CSV_IN  = Path(base_path + train_four_classes_file)\n",
        "  TRAIN_CSV_OUT = Path(base_path + augm_path + train_four_classes_file)\n",
        "  # Dove salvare i nuovi file\n",
        "  OUT_IMG_DIR = Path(augm_train_dir)\n",
        "  # -----------------------------\n",
        "  # CONFIG\n",
        "  # -----------------------------\n",
        "  SEED = 42\n",
        "  random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "  # Modalità CSV out: \"w\" per riscrivere tutto (originali + augment), \"a\" per appendere solo le nuove righe\n",
        "  CSV_MODE = \"w\"\n",
        "  WRITE_HEADER = True if CSV_MODE == \"w\" else False\n",
        "  \n",
        "  # Se la cartella di output contiene già immagini aumentate, salta tutto\n",
        "  if OUT_IMG_DIR.exists() and any(OUT_IMG_DIR.glob(\"*.png\")):\n",
        "      print(f\"Data augmentation già eseguita: trovate immagini in {OUT_IMG_DIR}.\")\n",
        "      print(\"Salto la rigenerazione e uso i file esistenti.\")\n",
        "  else:\n",
        "    OUT_IMG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    # Colonna per l'output: \"id_code\" (consigliato se il tuo Dataset fa f\"{id_code}.jpg\") oppure \"filepath\"\n",
        "    OUTPUT_USES_ID_CODE = True\n",
        "\n",
        "    augment = FundusAugment(img_size=preprocess_out_size)\n",
        "\n",
        "    # -----------------------------\n",
        "    # CARICA CSV E CONTA PER CLASSE\n",
        "    # -----------------------------\n",
        "    df_in = load_df(TRAIN_CSV_IN)\n",
        "    df_in[\"diagnosis\"] = df_in[\"diagnosis\"].astype(int)\n",
        "\n",
        "    # calcola counts per classe dal CSV\n",
        "    counts = df_in.groupby(\"diagnosis\").size().to_dict()\n",
        "    all_classes = sorted(df_in[\"diagnosis\"].unique().tolist())\n",
        "    if TARGET_PER_CLASS is None:\n",
        "      TARGET_PER_CLASS = max(counts.values())\n",
        "\n",
        "    print(\"Conteggi iniziali:\", counts)\n",
        "    print(\"Target per classe:\", TARGET_PER_CLASS)\n",
        "\n",
        "    # mappa: classe -> lista (id_code, path)\n",
        "    by_class = {c: [] for c in all_classes}\n",
        "    for _, row in df_in.iterrows():\n",
        "      p = row_to_path(row, TRAIN_IMG_DIR)\n",
        "      if p is None or not p.exists():\n",
        "        # salta righe orfane\n",
        "        continue\n",
        "      if \"id_code\" in df_in.columns:\n",
        "        by_class[row[\"diagnosis\"]].append((str(row[\"id_code\"]), p))\n",
        "      else:\n",
        "        # crea un id_code dal filename (senza estensione)\n",
        "        by_class[row[\"diagnosis\"]].append((p.stem, p))\n",
        "\n",
        "    # contatori per generare suffissi univoci per ciascun id_code base\n",
        "    per_id_counters = {}\n",
        "\n",
        "    # -----------------------------\n",
        "    # PREPARA CSV DI OUTPUT\n",
        "    # -----------------------------\n",
        "    TRAIN_CSV_OUT.parent.mkdir(parents=True, exist_ok=True)\n",
        "    mode = CSV_MODE\n",
        "    write_header = WRITE_HEADER\n",
        "    fout = open(TRAIN_CSV_OUT, mode, newline=\"\", encoding=\"utf-8\")\n",
        "    writer = csv.writer(fout)\n",
        "\n",
        "    # Decidi intestazioni e funzione che scrive una riga\n",
        "    if OUTPUT_USES_ID_CODE:\n",
        "      if write_header:\n",
        "        writer.writerow([\"id_code\", \"diagnosis\"])\n",
        "      def write_row_id(id_code: str, diagnosis: int):\n",
        "        writer.writerow([id_code, diagnosis])\n",
        "    else:\n",
        "      if write_header:\n",
        "        writer.writerow([\"filepath\", \"diagnosis\"])\n",
        "      def write_row_path(path: Path, diagnosis: int):\n",
        "        writer.writerow([str(path), diagnosis])\n",
        "\n",
        "  # se stai riscrivendo tutto, copia anche le righe originali nel nuovo CSV\n",
        "    if mode == \"w\":\n",
        "      for c in all_classes:\n",
        "          for id_code, path in by_class[c]:\n",
        "            if OUTPUT_USES_ID_CODE:\n",
        "                write_row_id(id_code, c)\n",
        "            else:\n",
        "                write_row_path(path, c)\n",
        "\n",
        "  # -----------------------------\n",
        "  # GENERA AUGMENT PER RAGGIUNGERE IL TARGET\n",
        "  # -----------------------------\n",
        "    for c in all_classes:\n",
        "      current = len(by_class[c])\n",
        "      need = max(0, TARGET_PER_CLASS - current)\n",
        "      if need == 0:\n",
        "        continue\n",
        "\n",
        "      print(f\"Classe {c}: genero {need} immagini…\")\n",
        "      src_items = by_class[c]\n",
        "      if not src_items:\n",
        "        continue\n",
        "\n",
        "      for i in tqdm(range(need), desc=f\"Augment class {c}\"):\n",
        "        base_id, src_path = random.choice(src_items)\n",
        "        with Image.open(src_path) as im:\n",
        "            im = im.convert(\"RGB\")\n",
        "            aug_img = augment(im)\n",
        "\n",
        "        # genera nome univoco\n",
        "        k = per_id_counters.get(base_id, 0)\n",
        "        per_id_counters[base_id] = k + 1\n",
        "        new_id = f\"{base_id}aug{k:05d}\"\n",
        "        out_path = OUT_IMG_DIR / f\"{new_id}.png\"\n",
        "\n",
        "        # evita collisioni nel raro caso il file esista\n",
        "        while out_path.exists():\n",
        "            k += 1\n",
        "            per_id_counters[base_id] = k + 1\n",
        "            new_id = f\"{base_id}aug{k:05d}\"\n",
        "            out_path = OUT_IMG_DIR / f\"{new_id}.png\"\n",
        "\n",
        "        aug_img.save(out_path, format=\"PNG\", quality=92, optimize=True, progressive=True)\n",
        "\n",
        "        # scrivi riga CSV per la nuova immagine\n",
        "        if OUTPUT_USES_ID_CODE:\n",
        "            write_row_id(new_id, c)\n",
        "        else:\n",
        "            write_row_path(out_path, c)\n",
        "\n",
        "    src = Path(processed_train_dir)\n",
        "    dst = Path(augm_train_dir)\n",
        "\n",
        "    # Copia tutto il contenuto (anche sottocartelle e file)\n",
        "    shutil.copytree(src, dst, dirs_exist_ok=True)\n",
        "    fout.close()\n",
        "    print(f\"Immagini nuove in: {OUT_IMG_DIR}\")\n",
        "    print(f\"CSV scritto in: {TRAIN_CSV_OUT}\")\n",
        "else:\n",
        "  augm_train_dir = processed_train_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load image names and labes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vn59LssWGnD7"
      },
      "outputs": [],
      "source": [
        "labels_train_binary = pd.read_csv(base_path + train_binary_file)\n",
        "labels_val_binary = pd.read_csv(base_path + val_binary_file)\n",
        "labels_test_binary = pd.read_csv(base_path + test_binary_file)\n",
        "\n",
        "labels_train_four_classes = pd.read_csv(base_path + augm_path + train_four_classes_file)\n",
        "labels_val_four_classes = pd.read_csv(base_path + val_four_classes_file)\n",
        "labels_test_four_classes = pd.read_csv(base_path + test_four_classes_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_dataset_statistics(msg: str, train_labels, val_labels, test_labels):\n",
        "    table_cnt = pd.DataFrame({\n",
        "        'TRAIN': train_labels['diagnosis'].value_counts().sort_index(),\n",
        "        'TEST': val_labels['diagnosis'].value_counts().sort_index(),\n",
        "        'VALIDATION': test_labels['diagnosis'].value_counts().sort_index()\n",
        "    }).T\n",
        "\n",
        "    table_perc = pd.DataFrame({\n",
        "    'TRAIN': round(train_labels['diagnosis'].value_counts(normalize=True).sort_index() * 100, 3),\n",
        "    'TEST': round(val_labels['diagnosis'].value_counts(normalize=True).sort_index() * 100, 3),\n",
        "    'VALIDATION': round(test_labels['diagnosis'].value_counts(normalize=True).sort_index() * 100, 3)\n",
        "    }).T  # trasponi per avere i dataset come righe\n",
        "\n",
        "    # Mostra le tabella\n",
        "    print(msg)\n",
        "    print(\"Dataset count\")\n",
        "    print(table_cnt)\n",
        "    print(\"\\nDataset percentage\")\n",
        "    print(table_perc)\n",
        "\n",
        "    train_labels['diagnosis'].value_counts().plot(kind = 'bar', color = ['red', 'blue', 'green', 'cyan', 'purple'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show_dataset_statistics(\"Binary dataset:\", labels_train_binary, labels_val_binary, labels_test_binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show_dataset_statistics(\"Four classes dataset:\", labels_train_four_classes, labels_val_four_classes, labels_test_four_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9CSU5YYF9mU"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    #transforms.CenterCrop(img_size),\n",
        "    transforms.ToTensor(),               # convert to tensor [0,1]\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],      # ImageNet mean\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HW_TbWciGIX-"
      },
      "outputs": [],
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, img_dir, labels_df, transform=None, preload=True):\n",
        "        self.img_dir = img_dir\n",
        "        self.labels_df = labels_df\n",
        "        self.transform = transform\n",
        "        self.preload = preload\n",
        "\n",
        "        # Map filenames and labels\n",
        "        self.filenames = self.labels_df['id_code'].values\n",
        "        self.labels = self.labels_df['diagnosis'].values\n",
        "\n",
        "        self.images = []  # qui salveremo le immagini pre-caricate\n",
        "\n",
        "        if self.preload:\n",
        "            print(\"Caricamento immagini in RAM...\")\n",
        "            for fname in tqdm(self.filenames, desc=\"Caricamento immagini\", unit=\"img\"):\n",
        "                img_path = os.path.join(self.img_dir, fname + \".png\")\n",
        "                image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "                if self.transform:\n",
        "                    image = self.transform(image)\n",
        "\n",
        "                self.images.append(image)\n",
        "            print(f\"Caricate {len(self.images)} immagini in memoria.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.preload:\n",
        "            image = self.images[idx]\n",
        "        else:\n",
        "            img_path = os.path.join(self.img_dir, self.filenames[idx] + \".png\")\n",
        "            image = Image.open(img_path).convert(\"RGB\")\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # If label is not numeric, convert to class index\n",
        "        if isinstance(label, str):\n",
        "            # Optional: map string labels to integers\n",
        "            # You can build a mapping outside this class\n",
        "            raise ValueError(\"Labels are strings. Convert them to int first.\")\n",
        "\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda') # Uncomment this to run on GPU\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_cuda_devices = torch.cuda.device_count()\n",
        "print(f\"CUDA è disponibile. Numero di dispositivi GPU: {num_cuda_devices}\")\n",
        "\n",
        "# (Opzionale) Stampa il nome di ciascun dispositivo\n",
        "for i in range(num_cuda_devices):\n",
        "    print(f\"Dispositivo {i}: {torch.cuda.get_device_name(i)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create datasets and loaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Caricamento dataset sulla RAM (set FALSE se non vuoi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZLrhMG_GTKG"
      },
      "outputs": [],
      "source": [
        "if local_runtime==1:\n",
        "    train_set_preload = True\n",
        "else:\n",
        "    train_set_preload = False\n",
        "\n",
        "train_set_preload = False\n",
        "\n",
        "train_set_binary = CustomImageDataset(augm_train_dir, labels_train_binary, transform=transform, preload=train_set_preload)\n",
        "train_loader_binary = DataLoader(train_set_binary, batch_size=batch_size, shuffle=True)\n",
        "val_set_binary = CustomImageDataset(processed_val_dir, labels_val_binary, transform=transform, preload=False)\n",
        "val_loader_binary = DataLoader(val_set_binary, batch_size=batch_size, shuffle=False)\n",
        "test_set_binary = CustomImageDataset(processed_test_dir, labels_test_binary, transform=transform, preload=False)\n",
        "test_loader_binary = DataLoader(test_set_binary, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "train_set_four_classes = CustomImageDataset(augm_train_dir, labels_train_four_classes, transform=transform, preload=train_set_preload)\n",
        "train_loader_four_classes = DataLoader(train_set_four_classes, batch_size=batch_size, shuffle=True)\n",
        "val_set_four_classes = CustomImageDataset(processed_val_dir, labels_val_four_classes, transform=transform, preload=False)\n",
        "val_loader_four_classes = DataLoader(val_set_four_classes, batch_size=batch_size, shuffle=False)\n",
        "test_set_four_classes = CustomImageDataset(processed_test_dir, labels_test_four_classes, transform=transform, preload=False)\n",
        "test_loader_four_classes = DataLoader(test_set_four_classes, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "GU4ryg7WIXlQ",
        "outputId": "042f893c-0c9e-4f64-b3aa-5999130fe1c6"
      },
      "outputs": [],
      "source": [
        "# Get one batch from the DataLoader\n",
        "images, labels = next(iter(train_loader_four_classes))  # images: [B, 3, 224, 224], labels: [B]\n",
        "\n",
        "# Denormalize for display (undo ImageNet normalization)\n",
        "mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "images = images * std + mean  # undo normalization\n",
        "\n",
        "# Make a grid of images\n",
        "grid = torchvision.utils.make_grid(images[:8], nrow=4)  # first 8 images, 4 per row\n",
        "\n",
        "# Convert to numpy for matplotlib (C,H,W -> H,W,C)\n",
        "grid_np = grid.permute(1, 2, 0).numpy()\n",
        "\n",
        "# Plot the images\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(grid_np)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Print corresponding labels\n",
        "print(\"Labels:\", labels[:8].tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Subset Loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In samples_per_class decidere quanti samples prendere per avere una distribuzione equa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def create_subset_loader(train_labels, train_set):\n",
        "    num_classes = 5\n",
        "    samples_per_class = 700\n",
        "\n",
        "    # Dictionary to hold indices for each class\n",
        "    class_indices = {c: [] for c in range(num_classes)}\n",
        "\n",
        "    # Iterate through dataset and collect indices by class\n",
        "    for idx, row in train_labels.iterrows():\n",
        "        label = int(row['diagnosis'])\n",
        "        class_indices[label].append(idx)\n",
        "\n",
        "    # For each class, randomly sample X indices\n",
        "    subset_indices = []\n",
        "    for c in range(num_classes):\n",
        "        chosen = np.random.choice(class_indices[c], samples_per_class, replace=False)\n",
        "        subset_indices.extend(chosen)\n",
        "\n",
        "    # Shuffle the final list of subset indices\n",
        "    np.random.shuffle(subset_indices)\n",
        "\n",
        "    # Create a subset of the dataset\n",
        "    subset_dataset = Subset(train_set, subset_indices)\n",
        "\n",
        "    # Create a new DataLoader for the subset\n",
        "    return DataLoader(subset_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Error with subset loader, beacuse now it has consider that binary classification only has 2 classes, and multiclass only has 4.\n",
        "# So we would need to update the method create_subset_loader to address that\n",
        "if use_subset_loader == 1:\n",
        "    loader_selected_binary = create_subset_loader(train_labels = labels_train_binary, train_set = train_set_binary)\n",
        "    loader_selected_four_classes = create_subset_loader(train_labels = labels_train_four_classes, train_set = train_set_four_classes)\n",
        "else:\n",
        "    loader_selected_binary = train_loader_binary\n",
        "    loader_selected_four_classes = train_loader_four_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if use_subset_loader == 1:\n",
        "    labels_check = []\n",
        "    for _, label in loader_selected_binary:\n",
        "        labels_check.append(int(label))\n",
        "\n",
        "    print(\"Class distribution in binary subset:\", Counter(labels_check))\n",
        "\n",
        "    labels_check = []\n",
        "    for _, label in loader_selected_four_classes:\n",
        "        labels_check.append(int(label))\n",
        "\n",
        "    print(\"Class distribution in four classes subset:\", Counter(labels_check))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper function for model training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_optimizer(\n",
        "    name: str,\n",
        "    params,\n",
        "    lr: None\n",
        ") -> optim.Optimizer:\n",
        "    \"\"\"\n",
        "    Crea un optimizer da stringa. Esempi:\n",
        "    'adam', 'sgd', 'adamw', 'rmsprop', 'adagrad'\n",
        "    opt_kwargs: qualunque parametro aggiuntivo (es. weight_decay, momentum...)\n",
        "    \"\"\"\n",
        "    name = name.strip().lower()\n",
        "    if name == \"adam\":\n",
        "        if lr is None:\n",
        "            return optim.Adam(params)\n",
        "        else:\n",
        "            return optim.Adam(params, lr=lr)\n",
        "    if name == \"adamw\":\n",
        "        if lr is None:\n",
        "            return optim.AdamW(params)\n",
        "        else:\n",
        "            return optim.AdamW(params, lr=lr)\n",
        "    if name == \"sgd\":\n",
        "        if lr is None:\n",
        "            return optim.SGD(params)\n",
        "        else:\n",
        "            return optim.SGD(params, lr=lr)\n",
        "    if name == \"rmsprop\":\n",
        "        if lr is None:\n",
        "            return optim.RMSprop(params)\n",
        "        else:\n",
        "            return optim.RMSprop(params, lr=lr)\n",
        "    if name == \"adagrad\":\n",
        "        if lr is None:\n",
        "            return optim.Adagrad(params)\n",
        "        else:\n",
        "            return optim.Adagrad(params, lr=lr)\n",
        "    raise ValueError(f\"Optimizer sconosciuto: '{name}'\")\n",
        "\n",
        "def is_focal_loss(\n",
        "    name: str\n",
        ") -> nn.Module:\n",
        "    name = name.strip().lower()\n",
        "    if name in (\"focal\", \"focallos\"):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def build_criterion(\n",
        "    name: str\n",
        ") -> nn.Module:\n",
        "    \"\"\"\n",
        "    Crea una loss da stringa. Esempi:\n",
        "    'crossentropy', 'bcelogits', 'mse', 'nll', 'smoothl1'\n",
        "    loss_kwargs: parametri extra (es. weight, reduction, label_smoothing...)\n",
        "    \"\"\"\n",
        "    name = name.strip().lower()\n",
        "    if name in (\"crossentropy\", \"crossentropyloss\", \"ce\"):\n",
        "        return nn.CrossEntropyLoss()\n",
        "    if name in (\"bcelogits\", \"bcelosslogits\", \"bcelogitsloss\"):\n",
        "        return nn.BCEWithLogitsLoss()\n",
        "    if name in (\"bce\", \"bceloss\"):\n",
        "        return nn.BCELoss()\n",
        "    if name in (\"bce_logits\"):\n",
        "        return nn.BCEWithLogitsLoss()\n",
        "    if name in (\"mse\", \"mseloss\", \"l2\"):\n",
        "        return nn.MSELoss()\n",
        "    if name in (\"nll\", \"nllloss\"):\n",
        "        return nn.NLLLoss()\n",
        "    if name in (\"smoothl1\", \"huber\"):\n",
        "        return nn.SmoothL1Loss()\n",
        "    if is_focal_loss(name):\n",
        "        return FocalLoss(gamma=2.0)\n",
        "    raise ValueError(f\"Criterion sconosciuto: '{name}'\")\n",
        "\n",
        "def build_scheduler(name: str, optimizer) -> nn.Module:\n",
        "    name = name.strip().lower()\n",
        "    if name in (\"reducelronplateau\"):\n",
        "        return ReduceLROnPlateau(\n",
        "            optimizer,\n",
        "            mode='min',       # because we want to minimize val_loss\n",
        "            factor=0.3,       # reduce LR by 0.3\n",
        "            patience=2,       # wait 2 epochs before reducing LR\n",
        "        )\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def multiclass_accuracy(outputs: torch.Tensor, targets: torch.Tensor) -> float:\n",
        "    \"\"\"\n",
        "    Calcola l'accuracy per classificazione multi-classe (es. 5 classi).\n",
        "    outputs: tensor [N, num_classes]\n",
        "    targets: tensor [N]\n",
        "    \"\"\"\n",
        "    preds = outputs.argmax(dim=1)\n",
        "    correct = (preds == targets).sum().item()\n",
        "    total = targets.size(0)\n",
        "    return correct / max(1, total)\n",
        "\n",
        "def binary_accuracy(outputs: torch.Tensor, targets: torch.Tensor) -> float:\n",
        "    \"\"\"\n",
        "    Calcola l'accuracy per classificazione binaria.\n",
        "    outputs: tensor [N, 1] o [N]\n",
        "    targets: tensor [N] - etichette binarie (0 o 1)\n",
        "    \"\"\"\n",
        "    preds = (outputs >= 0.5).long().view(-1)\n",
        "    correct = (preds == targets.long()).sum().item()\n",
        "    total = targets.size(0)\n",
        "    return correct / max(1, total)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(\n",
        "    model: nn.Module,\n",
        "    train_loader: torch.utils.data.DataLoader,\n",
        "    val_loader: None,\n",
        "    optimizer_name: \"adam\",\n",
        "    criterion_name: \"crossentropy\",\n",
        "    lr: None,\n",
        "    num_epochs: 5,\n",
        "    device: None,\n",
        "    scheduler_name = \"\",\n",
        "    verbose: bool = True,\n",
        "    model_output_softmax = False,\n",
        "    model_output_binary = False\n",
        ") -> Dict[str, List[float]]:\n",
        "    \"\"\"\n",
        "    Esegue training (e opzionalmente validazione) per num_epochs.\n",
        "    Ritorna uno storico con 'step_losses', 'epoch_losses', 'val_losses'.\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = build_criterion(criterion_name)\n",
        "    optimizer = build_optimizer(optimizer_name, model.parameters(), lr=lr)\n",
        "    uses_focal_loss = is_focal_loss(criterion_name)\n",
        "    scheduler = build_scheduler(scheduler_name, optimizer)\n",
        "\n",
        "    history = {\n",
        "        \"step_losses\": [],\n",
        "        \"epoch_losses\": [],\n",
        "        \"val_losses\": [],\n",
        "        \"epoch_acc\": [],\n",
        "        \"val_acc\": []\n",
        "    }\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "            train_iter = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
        "        else:\n",
        "            train_iter = enumerate(train_loader)\n",
        "\n",
        "        for _, (images, labels) in train_iter:\n",
        "            if criterion_name == \"bce_logits\":\n",
        "                labels = labels.float().to(device)\n",
        "            else:\n",
        "                labels = labels.to(device)\n",
        "            \n",
        "            images = images.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            if uses_focal_loss and not model_output_softmax:\n",
        "                loss = criterion(torch.softmax(outputs, dim=-1), labels)\n",
        "            else:\n",
        "                loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # --- metriche ---\n",
        "            is_binary_output = (\n",
        "                outputs.dim() == 1 or\n",
        "                (outputs.dim() == 2 and outputs.size(1) == 1)\n",
        "            )\n",
        "\n",
        "            if model_output_binary:\n",
        "                acc = binary_accuracy(outputs, labels)\n",
        "            else:\n",
        "                acc = multiclass_accuracy(outputs, labels)\n",
        "            correct_train += acc * labels.size(0)\n",
        "            total_train += labels.size(0)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            history[\"step_losses\"].append(loss.item())\n",
        "\n",
        "            if verbose:\n",
        "                if hasattr(train_iter, \"set_description\"):\n",
        "                    train_iter.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "                if hasattr(train_iter, \"set_postfix\"):\n",
        "                    train_iter.set_postfix(loss=loss.item(), acc=acc)\n",
        "\n",
        "        avg_epoch_loss = epoch_loss / max(1, len(train_loader))\n",
        "        epoch_acc = correct_train / max(1, total_train)\n",
        "        history[\"epoch_losses\"].append(avg_epoch_loss)\n",
        "        history[\"epoch_acc\"].append(epoch_acc)\n",
        "\n",
        "        # Validazione (se fornito val_loader)\n",
        "        if val_loader is not None:\n",
        "            model.eval()\n",
        "            val_loss_total = 0.0\n",
        "            correct_val = 0\n",
        "            total_val = 0\n",
        "            n_val_batches = 0\n",
        "            with torch.no_grad():\n",
        "                val_iter = tqdm(val_loader, total=len(val_loader), leave=False) if verbose else val_loader\n",
        "                for X_val, Y_val in val_iter:\n",
        "                    X_val = X_val.to(device)\n",
        "\n",
        "                    # change labels type if binary loss\n",
        "                    if criterion_name == \"bce_logits\" or criterion_name == \"bce\":\n",
        "                        Y_val = Y_val.float().to(device)\n",
        "                    else:\n",
        "                        Y_val = Y_val.to(device)\n",
        "\n",
        "                    Y_pred_val = model(X_val)\n",
        "                    \n",
        "                    if uses_focal_loss:\n",
        "                        loss_val = criterion(torch.softmax(Y_pred_val, dim=-1), Y_val)\n",
        "                    else:\n",
        "                        loss_val = criterion(Y_pred_val, Y_val)\n",
        "\n",
        "                    val_loss_total += loss_val.item()\n",
        "\n",
        "                    if model_output_binary:\n",
        "                        acc_val = binary_accuracy(Y_pred_val, Y_val)\n",
        "                    else:\n",
        "                        acc_val = multiclass_accuracy(Y_pred_val, Y_val)\n",
        "                    correct_val += acc_val * Y_val.size(0)\n",
        "                    total_val += Y_val.size(0)\n",
        "\n",
        "                    n_val_batches += 1\n",
        "\n",
        "            avg_val_loss = val_loss_total / max(1, n_val_batches)\n",
        "            val_acc = correct_val / max(1, total_val)\n",
        "            history[\"val_losses\"].append(avg_val_loss)\n",
        "            history[\"val_acc\"].append(val_acc)\n",
        "            if verbose:\n",
        "                print(f\"Epoch {epoch+1} training loss: {avg_epoch_loss:.4f} train acc={epoch_acc:.4f}, validation loss: {avg_val_loss:.4f} validation acc={val_acc:.4f}\")\n",
        "        else:\n",
        "            # se non c'è validazione, manteniamo lunghezze allineate\n",
        "            history[\"val_losses\"].append(float('nan'))\n",
        "            history[\"val_acc\"].append(float('nan'))\n",
        "            if verbose:\n",
        "                print(f\"Epoch {epoch+1} training loss: {avg_epoch_loss:.4f} train acc={epoch_acc:.4f}\")\n",
        "\n",
        "        # Step dello scheduler (se presente)\n",
        "        if scheduler is not None:\n",
        "            # Alcuni scheduler richiedono val_loss (es. ReduceLROnPlateau)\n",
        "            if hasattr(scheduler, 'step') and scheduler.__class__.__name__.lower().startswith('reducelronplateau'):\n",
        "                last_val = history[\"val_losses\"][-1]\n",
        "                # usa train loss se non c'è validazione\n",
        "                metric = last_val if not (last_val != last_val) else avg_epoch_loss\n",
        "                scheduler.step(metric)\n",
        "            else:\n",
        "                scheduler.step()\n",
        "\n",
        "    return history, model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_history(history, figsize=(15, 5), save_path=None, show=True):\n",
        "    \"\"\"\n",
        "    Mostra (e opzionalmente salva) tre grafici:\n",
        "      1. Step Losses (per batch)\n",
        "      2. Epoch Losses (train e validation)\n",
        "      3. Epoch Accuracy (train e validation)\n",
        "\n",
        "    Parametri\n",
        "    ----------\n",
        "    history : dict\n",
        "        Dizionario prodotto da train_model, con chiavi:\n",
        "            - \"step_losses\": perdite per batch\n",
        "            - \"epoch_losses\": perdite medie di training per epoca\n",
        "            - \"val_losses\": perdite medie di validazione per epoca\n",
        "            - \"epoch_acc\": accuracy di training per epoca\n",
        "            - \"val_acc\": accuracy di validazione per epoca\n",
        "    figsize : tuple\n",
        "        Dimensioni della figura (default: (15, 4))\n",
        "    save_path : str, opzionale\n",
        "        Se specificato, salva il grafico nel percorso indicato.\n",
        "    show : bool\n",
        "        Se True mostra il grafico (default: True)\n",
        "    title : str\n",
        "        Titolo generale della figura.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=figsize)\n",
        "\n",
        "    # --- Step losses (batch) ---\n",
        "    axes[0].plot(history[\"step_losses\"])\n",
        "    axes[0].set_title(\"Step Losses\")\n",
        "    axes[0].set_xlabel(\"Step\")\n",
        "    axes[0].set_ylabel(\"Loss\")\n",
        "\n",
        "    # --- Epoch losses (train + val) ---\n",
        "    axes[1].plot(history[\"epoch_losses\"], label=\"Training Loss\")\n",
        "    axes[1].plot(history[\"val_losses\"], label=\"Validation Loss\")\n",
        "    axes[1].set_title(\"Epoch Losses\")\n",
        "    axes[1].set_xlabel(\"Epoch\")\n",
        "    axes[1].set_ylabel(\"Loss\")\n",
        "    axes[1].legend()\n",
        "\n",
        "    axes[2].plot(history.get(\"epoch_acc\", []), label=\"Training Accuracy\", marker='o')\n",
        "    axes[2].plot(history.get(\"val_acc\", []), label=\"Validation Accuracy\", marker='o')\n",
        "    axes[2].set_title(\"Epoch Accuracy\")\n",
        "    axes[2].set_xlabel(\"Epoch\")\n",
        "    axes[2].set_ylabel(\"Accuracy\")\n",
        "    axes[2].set_ylim(0, 1)\n",
        "    axes[2].legend()\n",
        "    #axes[2].grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300)\n",
        "    if show:\n",
        "        plt.show()\n",
        "\n",
        "    return fig, axes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(\n",
        "    model,\n",
        "    test_loader,\n",
        "    average: str = \"macro\",\n",
        "    show_confusion: bool = False\n",
        "):\n",
        "    \"\"\"\n",
        "    Valuta il modello sul test set e restituisce le metriche principali.\n",
        "\n",
        "    Parametri\n",
        "    ----------\n",
        "    model : torch.nn.Module\n",
        "        Il modello PyTorch da valutare.\n",
        "    test_loader : DataLoader\n",
        "        Dataloader del set di test.\n",
        "    average : str\n",
        "        Tipo di media per precision/recall/F1 (\"macro\", \"micro\", \"weighted\", \"binary\").\n",
        "    show_confusion : bool\n",
        "        Se True, stampa anche la matrice di confusione.\n",
        "\n",
        "    Ritorna\n",
        "    -------\n",
        "    metrics : dict\n",
        "        Dizionario con chiavi:\n",
        "        - \"accuracy\"\n",
        "        - \"precision\"\n",
        "        - \"recall\"\n",
        "        - \"f1\"\n",
        "        - \"confusion_matrix\" (se show_confusion=True)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "\n",
        "            is_binary_output = (\n",
        "                outputs.dim() == 1 or\n",
        "                (outputs.dim() == 2 and outputs.size(1) == 1)\n",
        "            )\n",
        "\n",
        "            if is_binary_output:\n",
        "                # caso binario: usa sigmoid + soglia 0.5\n",
        "                if outputs.dim() == 2 and outputs.size(1) == 1:\n",
        "                    outputs = outputs.squeeze(1)        # [B]\n",
        "                probs = torch.sigmoid(outputs)          # [B]\n",
        "                preds = (probs >= 0.5).long()           # 0/1\n",
        "            else:\n",
        "                # caso multi-classe: argmax sui logit\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # --- Calcolo metriche ---\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    prec = precision_score(all_labels, all_preds, average=average, zero_division=0)\n",
        "    rec = recall_score(all_labels, all_preds, average=average, zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average=average, zero_division=0)\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": prec,\n",
        "        \"recall\": rec,\n",
        "        \"f1\": f1,\n",
        "    }\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    if show_confusion:\n",
        "        metrics[\"confusion_matrix\"] = cm\n",
        "        print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "    print(f\"Test Accuracy: {acc * 100:.2f}% | Precision: {prec:.3f} | Recall: {rec:.3f} | F1: {f1:.3f}\")\n",
        "\n",
        "    return metrics, cm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cleanup_torch_env(model_name: None):\n",
        "    \"\"\"\n",
        "    Pulisce in sicurezza l'ambiente PyTorch:\n",
        "    - Sposta il modello su CPU (se esiste)\n",
        "    - Elimina l'optimizer (se esiste)\n",
        "    - Elimina eventuali variabili temporanee note\n",
        "    - Esegue garbage collection e svuota la cache GPU\n",
        "\n",
        "    Parametri\n",
        "    ----------\n",
        "    model_name : str\n",
        "        Nome della variabile modello da spostare su CPU.\n",
        "    optimizer_name : str\n",
        "        Nome della variabile optimizer da eliminare.\n",
        "    \"\"\"\n",
        "    # --- Sposta modello su CPU ---\n",
        "    if model_name in globals():\n",
        "        globals()[model_name] = globals()[model_name].cpu()\n",
        "    elif model_name in locals():\n",
        "        locals()[model_name] = locals()[model_name].cpu()\n",
        "\n",
        "    # --- Cancella variabili temporanee ---\n",
        "    temp_vars = [\n",
        "        'outputs', 'loss', 'images', 'labels',\n",
        "        'Y_pred_val', 'X_val', 'Y_val',\n",
        "        'sample_preds_labels', 'sample_labels',\n",
        "        'sample_images', 'sample_preds',\n",
        "        'all_labels', 'all_preds'\n",
        "    ]\n",
        "\n",
        "    for var in temp_vars:\n",
        "        if var in globals():\n",
        "            del globals()[var]\n",
        "        elif var in locals():\n",
        "            del locals()[var]\n",
        "\n",
        "    # --- Garbage collector e cache GPU ---\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid search helpers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Definire in una griglia tutti i parametri che si vogliono testare: diversi optimizer (SGD, Adam, AdamW), diversi learning rates ecc. La funzione andrà a provare tutte le combinazioni possibili dei parametri inseriti nella griglia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def set_seed(seed: int = 42):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "def fig_to_base64(fig) -> str:\n",
        "    \"\"\"Converte una figura Matplotlib in stringa base64 PNG e chiude la figura.\"\"\"\n",
        "    buf = io.BytesIO()\n",
        "    fig.savefig(buf, format=\"png\", dpi=200, bbox_inches=\"tight\")\n",
        "    buf.seek(0)\n",
        "    b64 = base64.b64encode(buf.read()).decode(\"utf-8\")\n",
        "    plt.close(fig)\n",
        "    return b64\n",
        "\n",
        "def get_train_size(train_loader) -> int:\n",
        "    return len(train_loader.dataset)\n",
        "\n",
        "def run_experiments_to_single_csv(\n",
        "    model_fn: Callable[[], torch.nn.Module],\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    test_loader,\n",
        "    param_grid: Dict[str, List[Any]],\n",
        "    model_name: str = \"model\",\n",
        "    csv_folder = base_path+\"/results/\",\n",
        "    num_epochs: int = 5,\n",
        "    seed: int = 42,\n",
        "    device: Optional[torch.device] = None,\n",
        "    model_output_softmax = False\n",
        "    ):\n",
        "    os.makedirs(csv_folder, exist_ok=True)\n",
        "    \"\"\"\n",
        "    Esegue tutte le combinazioni e APPENDE una riga per run a un unico CSV.\n",
        "    La riga contiene: parametri, dimensioni train set, metriche test, cm (json), plot (base64).\n",
        "    \"\"\"\n",
        "    set_seed(seed)\n",
        "\n",
        "    keys = list(param_grid.keys())\n",
        "    combos = list(itertools.product(*(param_grid[k] for k in keys)))\n",
        "    print(f\"Partono {len(combos)} esperimenti...\\n\")\n",
        "\n",
        "    # Prepara CSV: scrivi header solo se non esiste\n",
        "    out_csv_path = csv_folder+model_name+\".csv\"\n",
        "    write_header = not os.path.exists(out_csv_path)\n",
        "\n",
        "    for i, values in enumerate(combos, 1):\n",
        "        params = {k: v for k, v in zip(keys, values)}\n",
        "        run_name = f\"{model_name}_run_{i:03d}_\" + \"_\".join(f\"{k}={v}\" for k, v in params.items())\n",
        "        print(f\"[{i}/{len(combos)}] {run_name}\")\n",
        "\n",
        "        # Nuovo modello per ogni run\n",
        "        model = model_fn()\n",
        "        train_size = get_train_size(train_loader)\n",
        "\n",
        "        # Train\n",
        "        history, model = train_model(\n",
        "                model=model,\n",
        "                train_loader=train_loader,\n",
        "                val_loader=val_loader,\n",
        "                optimizer_name=params[\"optimizer_name\"],\n",
        "                criterion_name=params[\"criterion_name\"],\n",
        "                scheduler_name=params[\"scheduler_name\"],\n",
        "                lr=params[\"lr\"],\n",
        "                num_epochs=num_epochs,\n",
        "                device=device,\n",
        "                model_output_softmax=model_output_softmax\n",
        "            )\n",
        "\n",
        "        # History -> plot -> base64 (niente salvataggi su disco)\n",
        "        plot_history(history, figsize=(15, 5), save_path=csv_folder+run_name+\".png\", show=False)\n",
        "\n",
        "        # Valutazione test (metriche + cm)\n",
        "        metrics, cm = evaluate_model(\n",
        "                model=model,\n",
        "                test_loader=test_loader,\n",
        "                average=\"macro\",\n",
        "                show_confusion=False\n",
        "            )\n",
        "\n",
        "        # Prepara riga per CSV (cm serializzata in JSON, plot come base64)\n",
        "        row = {\n",
        "                \"run_name\": run_name,\n",
        "                \"optimizer_name\": params[\"optimizer_name\"],\n",
        "                \"criterion_name\": params[\"criterion_name\"],\n",
        "                \"lr\": float(params[\"lr\"]),\n",
        "                \"num_epochs\": int(num_epochs),\n",
        "                \"train_size\": int(train_size),\n",
        "                \"seed\": int(seed),\n",
        "                \"device\": str(device),\n",
        "                \"test_accuracy\": float(metrics.get(\"accuracy\", float(\"nan\"))),\n",
        "                \"test_precision\": float(metrics.get(\"precision\", float(\"nan\"))),\n",
        "                \"test_recall\": float(metrics.get(\"recall\", float(\"nan\"))),\n",
        "                \"test_f1\": float(metrics.get(\"f1\", float(\"nan\"))),\n",
        "                \"confusion_matrix_json\": json.dumps(cm.tolist()),\n",
        "                \"graph_image_name\": str(run_name+\".png\")\n",
        "            }\n",
        "        \n",
        "        # Scrivi/append sul CSV\n",
        "        df = pd.DataFrame([row])\n",
        "        df.to_csv(out_csv_path, mode=\"a\", header=write_header, index=False)\n",
        "        write_header = False  # solo la prima volta\n",
        "\n",
        "        cleanup_torch_env(model)\n",
        "\n",
        "    print(f\"\\nTutte le run sono salvate in: {out_csv_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_binary = {\n",
        "        \"optimizer_name\": [\"sgd\"],\n",
        "        \"lr\": [0.001],\n",
        "        \"criterion_name\": [\"bce\"],\n",
        "        \"scheduler_name\": [\"\"]\n",
        "    }\n",
        "\n",
        "grid_four_classes = {\n",
        "        #\"optimizer_name\": [\"sgd\", \"adam\", \"adamw\"],\n",
        "        #\"lr\": [1e-4, 1e-3, 5e-3],\n",
        "        #\"criterion_name\": [\"crossentropy\", \"focal\"],\n",
        "        #\"scheduler_name\": [\"\"]\n",
        "        \"optimizer_name\": [\"sgd\"],\n",
        "        \"lr\": [0.001],\n",
        "        \"criterion_name\": [\"crossentropy\"],\n",
        "        \"scheduler_name\": [\"\"]\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Try a simple model for binary classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define the class\n",
        "\n",
        "class FMCNNBinary(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FMCNNBinary, self).__init__()\n",
        "        # creating the layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, stride=1, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(in_features=64*int(img_size/4)*int(img_size/4), out_features=128)\n",
        "        self.fc_bin = nn.Linear(in_features=128, out_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Employing the layers\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 64*int(img_size/4)*int(img_size/4))\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc_bin(x)\n",
        "\n",
        "        return x.squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = FMCNNBinary()\n",
        "print(model)\n",
        "summary(model, input_size=(batch_size, 3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history, model = train_model(\n",
        "    model = model,\n",
        "    train_loader = loader_selected_binary,\n",
        "    val_loader = val_loader_binary,\n",
        "    criterion_name = \"bce_logits\",\n",
        "    optimizer_name = \"adam\",\n",
        "    num_epochs = 20,\n",
        "    device = device,\n",
        "    lr=1e-3,\n",
        "    scheduler_name=\"\",\n",
        "    model_output_binary=True,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_history(history = history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics, cm = evaluate_model(\n",
        "    model,\n",
        "    test_loader_binary,\n",
        "    show_confusion=True,\n",
        "    average=\"binary\"\n",
        ")\n",
        "\n",
        "# Make predictions on a few sample images\n",
        "# Use the BINARY loader for the binary model\n",
        "sample_images, sample_labels = next(iter(test_loader_binary))\n",
        "\n",
        "sample_images = sample_images.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    sample_logits = model(sample_images)      # [B] or [B, 1]\n",
        "\n",
        "    if sample_logits.dim() == 2 and sample_logits.size(1) == 1:\n",
        "        sample_logits = sample_logits.squeeze(1)  # [B]\n",
        "\n",
        "    sample_probs = torch.sigmoid(sample_logits)   # [B]\n",
        "    sample_preds = (sample_probs >= 0.5).long()   # 0/1\n",
        "\n",
        "sample_preds_labels = sample_preds.cpu().numpy()\n",
        "\n",
        "print(\"Predicted labels:\", sample_preds_labels)\n",
        "print(\"True labels:\", sample_labels.numpy())\n",
        "\n",
        "imshow(torchvision.utils.make_grid(sample_images.cpu()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cleanup_torch_env(\"model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the first model (simple one), train and evaluate it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CCEE13wKsps",
        "outputId": "e0e11bad-f4c3-4e3f-ccee-06d1b678cda3"
      },
      "outputs": [],
      "source": [
        "# define the class\n",
        "\n",
        "class FMCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FMCNN, self).__init__()\n",
        "        # creating the layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, stride=1, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(in_features=64*int(img_size/4)*int(img_size/4), out_features=128)\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Employing the layers\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 64*int(img_size/4)*int(img_size/4))\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM6wDlBrE4FV",
        "outputId": "5d222e3e-5f27-426c-c42c-889949d55e0b"
      },
      "outputs": [],
      "source": [
        "model = FMCNN()\n",
        "print(model)\n",
        "summary(model, input_size=(1, 3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTD52zTNOYbA",
        "outputId": "8605a21b-9430-4605-8d0e-0a819e2aaa72"
      },
      "outputs": [],
      "source": [
        "history, model = train_model(\n",
        "    model = model,\n",
        "    train_loader = loader_selected_four_classes,\n",
        "    val_loader = val_loader_four_classes,\n",
        "    criterion_name = \"crossentropy\",\n",
        "    optimizer_name = \"adam\",\n",
        "    num_epochs = 5,\n",
        "    device = device,\n",
        "    lr=None,\n",
        "    scheduler_name=\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "OSu_TQ8O7-Ad",
        "outputId": "dcafe4b3-5d00-4ff4-e936-4ebab4361f24"
      },
      "outputs": [],
      "source": [
        "plot_history(history = history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "zZVpY0R_ZlIW",
        "outputId": "7ae7661a-bfac-4551-c9e0-0e51888c222e"
      },
      "outputs": [],
      "source": [
        "metrics, cm = evaluate_model(\n",
        "    model,\n",
        "    test_loader_four_classes,\n",
        "    show_confusion=True\n",
        ")\n",
        "\n",
        "# Make predictions on a few sample images\n",
        "sample_images, sample_labels = next(iter(test_loader_four_classes))\n",
        "sample_images = sample_images.to(device) # Move sample_images to the same device as the model\n",
        "sample_preds = model(sample_images)\n",
        "sample_preds_labels = torch.argmax(sample_preds, dim=1).cpu().numpy() # Move predictions back to CPU for numpy conversion\n",
        "\n",
        "print(\"Predicted labels:\", sample_preds_labels)\n",
        "print(\"True labels:\", sample_labels.numpy())\n",
        "\n",
        "imshow(torchvision.utils.make_grid(sample_images.cpu())) # Move images back to CPU for imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Libera la RAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cleanup_torch_env(\"model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Utilizzo della griglia dei parametri. Salva i risultati in un file .csv e le immagini nella cartella results "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "    return FMCNN()\n",
        "\n",
        "run_experiments_to_single_csv(\n",
        "        model_fn=model_fn,\n",
        "        train_loader=loader_selected_four_classes,\n",
        "        val_loader=val_loader_four_classes,\n",
        "        test_loader=test_loader_four_classes,\n",
        "        param_grid=grid_four_classes,\n",
        "        model_name=\"FMCNN\",\n",
        "        csv_folder = base_path+\"/results/\",\n",
        "        num_epochs=10,\n",
        "        device=device\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZMskfcz9uI7"
      },
      "source": [
        "## Test with another model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cvLMiFJ9zxe",
        "outputId": "127a6b47-3c3a-4abe-a60a-7a002d6e728f"
      },
      "outputs": [],
      "source": [
        "model_vgg16 = models.vgg16(weights=None, num_classes=5)\n",
        "\n",
        "print(model_vgg16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary(model_vgg16, input_size=(batch_size, 3, img_size, img_size))\n",
        "#                               (batch_size, channels, H, W)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZp2BKfR_bWt",
        "outputId": "dc3edb44-ce9f-46e2-f52d-40a2c6fb93c5"
      },
      "outputs": [],
      "source": [
        "history, model_vgg16 = train_model(\n",
        "    model = model_vgg16,\n",
        "    train_loader = loader_selected_four_classes,\n",
        "    val_loader = val_loader_four_classes,\n",
        "    optimizer_name = \"adam\",\n",
        "    criterion_name = \"crossentropy\",\n",
        "    lr=1e-4,\n",
        "    num_epochs = 5,\n",
        "    device = device,\n",
        "    scheduler_name = \"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "O7o0f5ELBRA_",
        "outputId": "450f7021-26ce-46af-b176-d0a88ce83b68"
      },
      "outputs": [],
      "source": [
        "plot_history(history = history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model_vgg16, base_path + \"model_vgg.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "id": "piw8rF_5BW2H",
        "outputId": "74a3e351-a498-4ff0-dee0-6f3b2399d57c"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "model2 = torch.load(base_path+\"model_vgg.pth\", weights_only=False)\n",
        "\n",
        "metrics, cm = evaluate_model(\n",
        "    model,\n",
        "    test_loader_four_classes,\n",
        "    show_confusion=True\n",
        ")\n",
        "\n",
        "# Make predictions on a few sample images\n",
        "sample_images, sample_labels = next(iter(test_loader_four_classes))\n",
        "sample_images = sample_images.to(device) # Move sample_images to the same device as the model\n",
        "sample_preds = model2(sample_images)\n",
        "sample_preds_labels = torch.argmax(sample_preds, dim=1).cpu().numpy() # Move predictions back to CPU for numpy conversion\n",
        "\n",
        "\n",
        "print(\"Predicted labels:\", sample_preds_labels)\n",
        "print(\"True labels:\", sample_labels.numpy())\n",
        "\n",
        "imshow(torchvision.utils.make_grid(sample_images.cpu())) # Move images back to CPU for imshow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cleanup_torch_env(\"model2\")\n",
        "cleanup_torch_env(\"model_vgg16\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "    return models.vgg16(weights=None, num_classes=5)\n",
        "\n",
        "run_experiments_to_single_csv(\n",
        "        model_fn=model_fn,\n",
        "        train_loader=loader_selected_four_classes,\n",
        "        val_loader=val_loader_four_classes,\n",
        "        test_loader=test_loader_four_classes,\n",
        "        param_grid=grid_four_classes,\n",
        "        model_name=\"vgg16\",\n",
        "        csv_folder = base_path+\"/results/\",\n",
        "        num_epochs=30,\n",
        "        device=device\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RSG-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RSGNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RSGNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, stride=1, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, stride=1, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, stride=1, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, stride=1, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(in_features=128*20*20, out_features=128)\n",
        "        self.bn1 = nn.BatchNorm1d(128)\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=5)\n",
        "        self.gap = nn.AdaptiveMaxPool2d(20)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Employing the layers\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(x)\n",
        "        #x = self.pool(x)\n",
        "        x = self.gap(x)\n",
        "        x = x.view(-1, 128*20*20)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        #x = F.softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "class RSGNet_Binary(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RSGNet_Binary, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, stride=1, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, stride=1, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, stride=1, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, stride=1, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(in_features=128*20*20, out_features=128)\n",
        "        self.bn1 = nn.BatchNorm1d(128)\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=1)\n",
        "        self.gap = nn.AdaptiveMaxPool2d(20)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Employing the layers\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.gap(x)\n",
        "        x = x.view(-1, 128*20*20)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.sigmoid(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Try a slightly different version, to try and overcome overfitting:\n",
        "- Early Stopping\n",
        "- LR scheduling: ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_rsg = RSGNet()\n",
        "print(model_rsg)\n",
        "summary(model_rsg, input_size=(batch_size, 3, img_size, img_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history, model_rsg = train_model(\n",
        "    model = model_rsg,\n",
        "    train_loader = train_loader_four_classes,\n",
        "    val_loader = val_loader_four_classes,\n",
        "    criterion_name = \"crossentropy\",\n",
        "    optimizer_name = \"sgd\",\n",
        "    lr=0.01,\n",
        "    num_epochs = 20,\n",
        "    device = device,\n",
        "    scheduler_name = \"reducelronplateau\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history, model_rsg = train_model(\n",
        "    model = model_rsg,\n",
        "    train_loader = train_loader_four_classes,\n",
        "    val_loader = val_loader_four_classes,\n",
        "    criterion_name = \"crossentropy\",\n",
        "    optimizer_name = \"sgd\",\n",
        "    lr=0.001,\n",
        "    num_epochs = 20,\n",
        "    device = device,\n",
        "    scheduler = None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_history(history = history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics, cm = evaluate_model(\n",
        "    model_rsg,\n",
        "    test_loader_four_classes,\n",
        "    show_confusion=True\n",
        ")\n",
        "\n",
        "# Make predictions on a few sample images\n",
        "sample_images, sample_labels = next(iter(test_loader_four_classes))\n",
        "sample_images = sample_images.to(device) # Move sample_images to the same device as the model\n",
        "sample_preds = model_rsg(sample_images)\n",
        "sample_preds_labels = torch.argmax(sample_preds, dim=1).cpu().numpy() # Move predictions back to CPU for numpy conversion\n",
        "\n",
        "\n",
        "print(\"Predicted labels:\", sample_preds_labels)\n",
        "print(\"True labels:\", sample_labels.numpy())\n",
        "\n",
        "imshow(torchvision.utils.make_grid(sample_images.cpu())) # Move images back to CPU for imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cleanup_torch_env(\"model_rsg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "    return RSGNet()\n",
        "\n",
        "run_experiments_to_single_csv(\n",
        "        model_fn=model_fn,\n",
        "        train_loader=loader_selected_four_classes,\n",
        "        val_loader=val_loader_four_classes,\n",
        "        test_loader=test_loader_four_classes,\n",
        "        param_grid=grid_four_classes,\n",
        "        model_name=\"RSGNet\",\n",
        "        csv_folder = base_path+\"/results/\",\n",
        "        num_epochs=30,\n",
        "        device=device,\n",
        "        model_output_softmax = False\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_resnet18 = models.resnet18(weights='DEFAULT')\n",
        "print(model_resnet18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_resnet18 = models.resnet18(weights='IMAGENET1K_V1')\n",
        "print(model_resnet18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(type(model_resnet18))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2) Replace the last layer (\"fc\") with number of classes (5)\n",
        "model_resnet18.fc = nn.Linear(model_resnet18.fc.in_features, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary(model_resnet18, input_size=( batch_size, 3, img_size, img_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history, model_resnet18 = train_model(\n",
        "    model = model_resnet18,\n",
        "    train_loader = train_loader_four_classes,\n",
        "    val_loader = val_loader_four_classes,\n",
        "    criterion_name = \"crossentropy\",\n",
        "    optimizer_name = \"sgd\",\n",
        "    lr=0.01,\n",
        "    num_epochs = 20,\n",
        "    device = device,\n",
        "    scheduler_name = \"reducelronplateau\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Simone's Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Legacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Simone(nn.Module):                                                                                                                                                                                \n",
        "    def __init__(self):\n",
        "        super(Simone, self).__init__()\n",
        "        # creating the layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, stride=1, kernel_size=3, padding=1)\n",
        "        self.dropout1 = nn.Dropout(p=0.2)  # 20% di dropout\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.dropout2 = nn.Dropout(p=0.2)  # 20% di dropout\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(in_features=128*int(img_size/4)*int(img_size/4), out_features=128)\n",
        "        self.dropout3 = nn.Dropout(p=0.5)  # 50% di dropout\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Employing the layers\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 128*int(img_size/4)*int(img_size/4))\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout3(x)  # applico dropout solo durante il training\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_simone = Simone()\n",
        "print(model_simone)\n",
        "summary(model_simone, input_size=(batch_size, 3, img_size, img_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history, model_simone = train_model(\n",
        "    model = model_simone,\n",
        "    train_loader = train_loader_four_classes,\n",
        "    val_loader = val_loader_four_classes,\n",
        "    criterion_name = \"crossentropy\",\n",
        "    optimizer = \"adam\",\n",
        "    lr=1e-3,\n",
        "    num_epochs = 30,\n",
        "    device = device,\n",
        "    scheduler_name=\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_history(history = history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics, cm = evaluate_model(\n",
        "    model_simone,\n",
        "    test_loader_four_classes,\n",
        "    show_confusion=True\n",
        ")\n",
        "\n",
        "# Make predictions on a few sample images\n",
        "sample_images, sample_labels = next(iter(test_loader_four_classes))\n",
        "sample_images = sample_images.to(device) # Move sample_images to the same device as the model\n",
        "sample_preds = model_simone(sample_images)\n",
        "sample_preds_labels = torch.argmax(sample_preds, dim=1).cpu().numpy() # Move predictions back to CPU for numpy conversion\n",
        "\n",
        "\n",
        "print(\"Predicted labels:\", sample_preds_labels)\n",
        "print(\"True labels:\", sample_labels.numpy())\n",
        "\n",
        "imshow(torchvision.utils.make_grid(sample_images.cpu())) # Move images back to CPU for imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cleanup_torch_env(\"model_simone\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "    return Simone()\n",
        "\n",
        "run_experiments_to_single_csv(\n",
        "        model_fn=model_fn,\n",
        "        train_loader=loader_selected_four_classes,\n",
        "        val_loader=val_loader_four_classes,\n",
        "        test_loader=test_loader_four_classes,\n",
        "        param_grid=grid_four_classes,\n",
        "        model_name=\"Simone\",\n",
        "        csv_folder = base_path+\"/results/\",\n",
        "        num_epochs=30,\n",
        "        device=device\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimoneBinary(nn.Module):                                                                                                                                                                                \n",
        "    def __init__(self):\n",
        "        super(SimoneBinary, self).__init__()\n",
        "        # creating the layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, stride=1, kernel_size=3, padding=1)\n",
        "        self.dropout1 = nn.Dropout(p=0.2)  # 20% di dropout\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.dropout2 = nn.Dropout(p=0.2)  # 20% di dropout\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(in_features=128*int(img_size/4)*int(img_size/4), out_features=128)\n",
        "        self.dropout3 = nn.Dropout(p=0.5)  # 50% di dropout\n",
        "        self.fc_binary = nn.Linear(in_features=128, out_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Employing the layers\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 128*int(img_size/4)*int(img_size/4))\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout3(x)  # applico dropout solo durante il training\n",
        "        x = self.fc_binary(x)\n",
        "\n",
        "        return x.squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_simone = SimoneBinary()\n",
        "print(model_simone)\n",
        "summary(model_simone, input_size=(batch_size, 3, img_size, img_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history, model_simone = train_model(\n",
        "    model = model_simone,\n",
        "    train_loader = train_loader_binary,\n",
        "    val_loader = val_loader_binary,\n",
        "    criterion_name = \"bce_logits\",\n",
        "    optimizer_name = \"adam\",\n",
        "    lr=1e-3,\n",
        "    num_epochs = 20,\n",
        "    device = device,\n",
        "    scheduler_name=\"\",\n",
        "    model_output_binary=True,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_history(history = history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics, cm = evaluate_model(\n",
        "    model_simone,\n",
        "    test_loader_binary,\n",
        "    show_confusion=True,\n",
        "    average=\"binary\"\n",
        ")\n",
        "\n",
        "# Make predictions on a few sample images\n",
        "# Use the BINARY loader for the binary model\n",
        "sample_images, sample_labels = next(iter(test_loader_binary))\n",
        "\n",
        "sample_images = sample_images.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    sample_logits = model_simone(sample_images)      # [B] or [B, 1]\n",
        "\n",
        "    if sample_logits.dim() == 2 and sample_logits.size(1) == 1:\n",
        "        sample_logits = sample_logits.squeeze(1)  # [B]\n",
        "\n",
        "    sample_probs = torch.sigmoid(sample_logits)   # [B]\n",
        "    sample_preds = (sample_probs >= 0.5).long()   # 0/1\n",
        "\n",
        "sample_preds_labels = sample_preds.cpu().numpy()\n",
        "\n",
        "print(\"Predicted labels:\", sample_preds_labels)\n",
        "print(\"True labels:\", sample_labels.numpy())\n",
        "\n",
        "imshow(torchvision.utils.make_grid(sample_images.cpu()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cleanup_torch_env(\"model_simone\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-class classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Simone4Class(nn.Module):                                                                                                                                                                                \n",
        "    def __init__(self):\n",
        "        super(Simone4Class, self).__init__()\n",
        "        # creating the layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, stride=1, kernel_size=3, padding=1)\n",
        "        self.dropout1 = nn.Dropout(p=0.2)  # 20% di dropout\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.dropout2 = nn.Dropout(p=0.2)  # 20% di dropout\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(in_features=128*int(img_size/4)*int(img_size/4), out_features=128)\n",
        "        self.dropout3 = nn.Dropout(p=0.5)  # 50% di dropout\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Employing the layers\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 128*int(img_size/4)*int(img_size/4))\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout3(x)  # applico dropout solo durante il training\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_simone = Simone4Class()\n",
        "print(model_simone)\n",
        "summary(model_simone, input_size=(batch_size, 3, img_size, img_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history, model_simone = train_model(\n",
        "    model = model_simone,\n",
        "    train_loader = train_loader_four_classes,\n",
        "    val_loader = val_loader_four_classes,\n",
        "    criterion_name = \"crossentropy\",\n",
        "    optimizer_name = \"adam\",\n",
        "    lr=1e-3,\n",
        "    num_epochs = 20,\n",
        "    device = device,\n",
        "    scheduler_name=\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_history(history = history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics, cm = evaluate_model(\n",
        "    model_simone,\n",
        "    test_loader_binary,\n",
        "    show_confusion=True\n",
        ")\n",
        "\n",
        "# Make predictions on a few sample images\n",
        "# Use the BINARY loader for the binary model\n",
        "sample_images, sample_labels = next(iter(test_loader_binary))\n",
        "\n",
        "sample_images = sample_images.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    sample_logits = model_simone(sample_images)      # [B] or [B, 1]\n",
        "\n",
        "    if sample_logits.dim() == 2 and sample_logits.size(1) == 1:\n",
        "        sample_logits = sample_logits.squeeze(1)  # [B]\n",
        "\n",
        "    sample_probs = torch.sigmoid(sample_logits)   # [B]\n",
        "    sample_preds = (sample_probs >= 0.5).long()   # 0/1\n",
        "\n",
        "sample_preds_labels = sample_preds.cpu().numpy()\n",
        "\n",
        "print(\"Predicted labels:\", sample_preds_labels)\n",
        "print(\"True labels:\", sample_labels.numpy())\n",
        "\n",
        "imshow(torchvision.utils.make_grid(sample_images.cpu()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Simone2's Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Simone2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.body = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
        "            nn.Conv2d(32,32,3,padding=1),   nn.BatchNorm2d(32), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32,64,3,padding=1),   nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.Conv2d(64,128,3,padding=1),  nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.gap = nn.AdaptiveAvgPool2d(10)  # output: (B,128,1,1)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128*10*10, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 4)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.body(x)\n",
        "        x = self.gap(x)\n",
        "        x = self.head(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_simone2 = Simone2()\n",
        "print(model_simone2)\n",
        "summary(model_simone2, input_size=(batch_size, 3, img_size, img_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history, model_simone2 = train_model(\n",
        "    model = model_simone2,\n",
        "    train_loader = train_loader_four_classes,\n",
        "    val_loader = val_loader_four_classes,\n",
        "    criterion_name = \"crossentropy\",\n",
        "    optimizer_name = \"adam\",\n",
        "    num_epochs = 5,\n",
        "    device = device,\n",
        "    scheduler_name=\"\",\n",
        "    lr=1e-3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_history(history = history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics, cm = evaluate_model(\n",
        "    model,\n",
        "    test_loader_four_classes,\n",
        "    show_confusion=True\n",
        ")\n",
        "\n",
        "# Make predictions on a few sample images\n",
        "sample_images, sample_labels = next(iter(test_loader_four_classes))\n",
        "sample_images = sample_images.to(device) # Move sample_images to the same device as the model\n",
        "sample_preds = model_simone2(sample_images)\n",
        "sample_preds_labels = torch.argmax(sample_preds, dim=1).cpu().numpy() # Move predictions back to CPU for numpy conversion\n",
        "\n",
        "\n",
        "print(\"Predicted labels:\", sample_preds_labels)\n",
        "print(\"True labels:\", sample_labels.numpy())\n",
        "\n",
        "imshow(torchvision.utils.make_grid(sample_images.cpu())) # Move images back to CPU for imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cleanup_torch_env(\"model_simone2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "    return Simone2()\n",
        "\n",
        "run_experiments_to_single_csv(\n",
        "        model_fn=model_fn,\n",
        "        train_loader=loader_selected_four_classes,\n",
        "        val_loader=val_loader_four_classes,\n",
        "        test_loader=test_loader_four_classes,\n",
        "        param_grid=grid_four_classes,\n",
        "        model_name=\"Simone2\",\n",
        "        csv_folder = base_path+\"/results/\",\n",
        "        num_epochs=5,\n",
        "        device=device\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Fn42OzLnZB-u"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
